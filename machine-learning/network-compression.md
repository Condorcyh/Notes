## 网络压缩



### 1. 概述

深度神经网络（DNN）已经被广泛的应用在了很多领域，但是令人望而却步的计算复杂度使得他们难以在移动设备上部署。 于是就有了神经网络压缩算法，可以把一个大小为 几百 M的模型压缩到不到10M。 然而，为这样的模型选择超参数来取得一个压缩效果很好的网络是十分困难的。 为了让DNN压缩技术更加简单的被应用并且减少对熟练的人类专家的需求。 自动神经网络压缩算法被提出了，在学术界和工业界都有着十分重大的影响力。



### 2. 分类

自动压缩问题在不同的限制下可以被大体上分成三种。

第一种是 硬件导向的模型压缩技术，用来去限制精度上的损失。 它不依赖于启发式和基于规则的策略， 这两种策略需要专家去手动的探索很大的搜索空间 并且对于模型的大小， 速度 和 准确率做出一些权衡。

**第二种是有 训练数据和老师网络的情况下的资源受限的自动模型压缩。 给出受限制的计算资源，核心的思想是去输入一个大型的老师网络 最终 输出一个相对比较小的 学生网络。**

第三种是   在有训练数据的情况下神经网络架构搜索。 这个问题在这三个压缩问题里面是最苦难的，因为我们必须去设计一个新颖的神经网络架构并且满足硬件资源的约束。



上面的三个任务中我目前负责第二个。

### 3. 目标

我们提出了一个算法来自动的找到最优的压缩策略，把确定的资源限制作为参数去输入。  我们把一个比较大型的学生网络作为输入并且将其压缩作为比较小的学生网络。 同时能够保持分类效果。 我们的算法不仅仅会考虑连续压缩率策略同时也会考虑把网络层移除的策略。



#### 4. 方法

随着现代的神经网络变得越来越深和越来越大，他们变得的越来越慢并且需要很高的计算资源，而普通的移动设备和终端设备并不会具备这种计算资源。

给出可以在移动设备上使用的受限制的计算资源，设计一个能够平衡资源效率和模型准确率的模型是非常苦难的。 进一步讲，每一种移动设备都有自己的软件和硬件特点，并且会需要不同的网络架构来做到最好的准确率和效率的平衡。

受到知识蒸馏这种使用不同的训练技巧去让一个小的网络模仿一个很大的网络并且可以和这个很大的网络能够在运行的时候去的相同的性能。  我们的方法使用一个大型的 老师网络 作为输入并且去输出一个压缩好的从老师网络中提取出来的学生网络。因为对于不同的任务修改网络架构师是十分困难的，所有我们通过引入强化学习的方法来对网络进行自动化的压缩。

我们的目标是在给定一个资源限制的情况下使用强化学习学习到一个最优的压缩策略，把一个老师网络作为输入，系统自动化的输出一个比较小的学生网络。 我们把这个序列化的去找到学生网络架构的过程作为一个决策的过程，并且分别定义了 状态空间，动作空间 和 reward. 更加具体的讲，这里有两类动作，把一层移除和让一个网络层有着更高的稀疏率。 我们想出了一个连续压缩率控制策略通过一个 DDPG agent. 我们的 reward 函数是基于准确率和预先定义好的硬件资源限制得出的。

我们应用一个两步的层移除和层压缩的过程去学习到怎样去自动的压缩一个大型的神经网络。 我们的方法和不仅仅会压缩层的数量同时也会去压缩每一层上的可训练参数。 进一步讲，我们加速了我们的网络层的收缩使用了一个简单的，非RNN的控制器和更快的探索使用连续的动作空间。



#### 5. 相关工作

对于第二个任务，已经有了很多基于知识蒸馏的工作。 知识蒸馏是通过一个大的预训练老师模型来取得一个比较小的，高准确率的学生网络的方法。

1. Hinton G., Vinyals O., Dean J. (2015). Distilling the knowledge in a neural network. arXiv preprint arXiv:1503.02531.
2. Ba, J., & Caruana, R. (2014). Do deep nets really need to be deep?. In Advances in neural information processing systems (pp. 2654-2662).
3. Chen, T., Goodfellow, I., & Shlens, J. (2015). Net2net: Accelerating learning via knowledge transfer. In International Conference on Learning Representations (ICLR’16).

上面是三个相关工作，在第一个论文中，作者展示了从一个 teacher 网络 和 给定数据区训练会比只使用数据区训练的效果好的多。 然后现在的知识蒸馏方法需要小心的设计学生网络。 我们训练了一个控制器去学习优化学生架构，而不是用手工设计的方法。

并且，之前的针对模型搜索的强化学习方法引入了基于RNN的网络通过 策略控制器的方法，但是这种方法非常消耗时间。

1. Ashok, A., Rhinehart, N., Beainy, F., Kitani, K.M.: N2n learning: Network to network compression via policy gradient reinforcement learning arXiv preprint arXiv:1709.06030 (2017)
2. Cai, H., Chen, T., Zhang, W., Yu, Y., Wang, J.: Reinforcement learning for architecture search by network transformation. arXiv preprint arXiv:1707.04873 (2017)

并且对于层的压缩率是离散的并且在限制在一定的范围内。 然而，我们发现模型压缩的准确率对于每一层的稀疏度十分敏感。 所以，我们引入了一个简单的 非 RNN 控制器 并且 定义了 一个连续的动作空间来应对我们每一层的压缩过程。



